## 1. 推拉概念

|      |                           定义                           |                            优缺点                            |
| :--: | :------------------------------------------------------: | :----------------------------------------------------------: |
|  推  |                事件触发后广播给所有的粉丝                | 对于粉丝数过多的事 件后台压力较大，浪费存储空间。流程清 晰，开发难度低，关注新用户需要同步更新feed流 |
|  拉  | 登陆打开页面的时候， 根据关注的实体动态 生成timeline内容 |                    读取压力大，存储占用小                    |
| 推拉 |                 活跃用户推， 其他用户拉                  |           降低存储空间，又满足大部分用户的读取需求           |

推：将feed流的id直接推给各个粉丝，粉丝查看新鲜事时直接通过feed ids 直接主键查询feed内容（或者redis数据库），效率高。

拉：先查看所有用户关注列表，然后通过userid in () 的方法

```sql
select * from table where column =1
union all
select * from table where column =2.....
#最好使用这种方式，可以使用column上的索引
```

所以其实userid in () 的方式还是多次扫描了表，效率较低。



## 2. flyweight设计模式

![image-20200629105304587](http://pyyf.oss-cn-hangzhou.aliyuncs.com/typora/202006/29/105304-473442.png)

## 3. 架构参考

### 3.1 微博

第一版

1. 纯推送，推送延迟，压力大，数据存储浪费
   - 用户多了，僵尸号特别多，推给僵尸号无意义

第二版

1. 推送给有效用户（当天登陆过的用户）

2. 大号拉，小号推，整合feed流
   - 粉丝量超过一百万的明星发了动态，只写数据库，粉丝量少于一百万的普通人的推给所有的粉丝
   - 我关注了20个人，其中粉丝量超过一百万的明星的动态从数据库拉，而一百万以下的普通人的动态推过来的，直接读

3. 按月时间拆分保存，索引每月微博边界
   - 数据库分库分表，用户看最新的动态较多，所以之前的数据和新的数据分开，如按月存储

4. 异步处理，发送成功先在自己流里可见
   - 自己先看到，对用户体验好，其他人则慢慢的推给他们，减少服务器瞬时压力

第三版

1. 服务化，feed按月，私信按uid拆分
   - 按服务进行分库分表

2. 分级缓存-热门，短期，历史微博
   - 热门的放内存，次热门放redis，不热门放数据库

3. 多机房数据同步  
   - 集群缓存涉及到数据同步问题

### 3.2人人网

1. 以推送为主，新鲜事合并
   - 多个用户都点赞了某个帖子，则显示 1 2 3点赞了
2. 内存缓存关系链
   - 数据都放内存缓存中进行存储
3. 数据压缩缓存quicklz
4. 异步线程池
5. flyweight  



## 4. 优化

1. 多好友合并去重
   - 多个用户都点赞了某个帖子，则显示 1 2 3点赞了
2. 关联实体删除清理
   - 点赞了后，我又取消了，应该从push的流中将feed删除
3. 取消/新增关注实时更新
   - 点赞了后，我又取消了，应该从push的流中将feed删除，关注了后应该将feed加上
4. 分时段存储
   - 分库分表
5. 缓存和增量拉 
   - 这一次拉到100，下次开始拉101-150，这种增量拉取，之前的就不拉了。



## 5. 实战

1. 为每个用户在redis中设置一个N~1~天内登录标记，如果用户一旦登录，则刷新标记，这样就可以快速判断用户是否N~1~天内登录过。
2. 存储：用户A发布、点赞、评论后，将feed流插入数据库中，并判断每个粉丝的N~1~天登录标记是否存在，如果存在则放入该粉丝的redis timeline中。
3. 读取：直接从redis timeline中取对应的id，如果能取到，则根绝这些id从mysql中进行主键查询，如果取不到，则通过mysql扫描将符合条件的feed流找出来返回。
4. 当用户删除帖子，取消点赞，删除评论时，
   1. 先在mysql中取出对应的feed（根据userId,type，postId），删除
   2. 然后根据这个feed从所有粉丝的redis timeline中删除该feed id
   3. 如果是取消关注用户则取出近N~2~天的feed，从A的timeline中移除。
5. 当用户发布、点赞、评论时，继续按照第二步的步骤。



设计方案：

1. N~1~：以N~1~天登录为界限，即用户N~1~天内登录过，则推，否则不推。

2. N~2~：以N~2~天的feed为期限，如果Redis中没有，则从Mysql中取，取多少呢？以N~2~为期限，用户所关注的所有对象N~2~天内发生的feed全部列举出来，并放入redis中

   2. 可以将所有id放入redis中，然后重定向一次，这次就直接从redis中取了。
   2. 返回第一页数据并异步放入redis中，从此就从redis取了，将page中的信息同样从redis中取（offset，limit）。

3. 如果用户一直活跃，那就会源源不断的向timeline中推数据，所以我们可以使用N~3~限制feed的容量，redis最多容纳N~3~(暂定160，即20页的feed，每页8条)，超过N~3~时，则循环弹出对头的feed。同时第二步从mysql中也是一次性取出N~2~的元素，如果过多，则取出前N~3~个id。（也就是队列需要同时满足N~2~和N~3~条件）

4. 目前缺陷：如果A关注了B，A一直在不间断登录，那B的动态就会一直在A的新鲜事中，即不存在上述设计方案的N~2~条件。导致当取消关注用户B时，则需要取出B所有的feed，依次从A的timeline中移除。

5. 每次向用户push时，先push进去，然后判断是否是N~2~天内的feed，如果是则弹出来；同时超过N~3~时，则弹出最老的feed。为了避免用户关注的人中，全部都凉了，那没有人往该用户push，那么就无法筛选，所以每次用户获取新鲜事时，也需要判断队列头部是否是N~2~天内的feed，如果是则弹出来；同时如果队列长度超过N~3~时，则循环弹出对头的feed

   